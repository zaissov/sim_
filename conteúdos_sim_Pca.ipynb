{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O que é o Principal Component Analysis (PCA)?\n",
    "\n",
    "Uma das técnicas mais utilizadas na redução de dimensionalidade é um método estatístico designado por Principal Component Analysis (PCA). O PCA é caracterizado por identificar as dimensões ao longo das quais os dados se encontram mais dispersos. Desta forma, conseguimos identificar as dimensões que melhor diferenciam o conjunto de dados em análise, ou seja, os seus componentes principais.\n",
    "\n",
    "Usando esta técnica, é possível realçar as semelhanças e diferenças neles existentes através da identificação de padrões. A sua identificação em dados caraterizados por grandes dimensões é difícil, uma vez que a sua representação gráfica não é viável, logo uma análise visual aos dados não é possível. Quando identificados os padrões no conjunto, o número de dimensões a analisar pode ser reduzido sem que haja uma perda significativa de informação, pois o foco recai sobre a análise das dimensões principais que caracterizam o conjunto de dados.\n",
    "\n",
    "Como aplicar o PCA a um conjunto de dados?\n",
    "Suponhamos que temos um conjunto de dados composto por duas dimensões (X e Y), tal como ilustrado na figura abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:[-2.5, -0.5, -2.2, -1.9, -3.1, -2.3, -2, -1, -1.5, -1.1]\n",
      "y:[2.4, 0.7, 2.9, 2.2, 3.0, 2.7, 1.6, 1.1, 1.6, 0.9]\n"
     ]
    }
   ],
   "source": [
    "x=[-2.5,-.5,-2.2,-1.9,-3.1,-2.3,-2,-1,-1.5,-1.1]\n",
    "y=[2.4,0.7,2.9,2.2,3.0,2.7,1.6,1.1,1.6,.9]\n",
    "print(f'x:{x}')\n",
    "print(f'y:{y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aplicar o PCA a este conjunto de dados é necessário executar os seguintes passos\n",
    "\n",
    "Média:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media (x)=[-0.69  1.31 -0.39 -0.09 -1.29 -0.49 -0.19  0.81  0.31  0.71]\n",
      "media (y)=[ 0.4 -1.3  0.9  0.2  1.   0.7 -0.4 -0.9 -0.4 -1.1]\n"
     ]
    }
   ],
   "source": [
    "x1= x-np.mean(x)\n",
    "y1= y-round(np.mean(y))\n",
    "print(f'media (x)={x1}')\n",
    "print(f'media (y)={y1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# º) Calcular a Matriz de Covariância\n",
    "\n",
    "A variância e a covariância são duas medidas utilizadas em estatística.\n",
    "A variância indica quão dispersos estão os dados de uma dimensão em relação à média, “ignorando” a existência de outras dimensões.\n",
    "A covariância, por sua vez, aplica-se a duas dimensões, permitindo assim perceber como ambas estão relacionadas entre si.\n",
    "Esta medida indica quanto as dimensões variam em relação à média, tendo em conta a relação que existe entre elas. \n",
    "Ao calcular a covariância entre duas dimensões, podemos deduzir como elas se relacionam entre si, ao efetuar a seguinte análise:\n",
    "\n",
    "•cov(X,Y) > 0: Se a covariância entre as dimensões X e Y for positiva, ambas as dimensões estão diretamente relacionadas entre si, ou seja, se os valores de X aumentam, os valores de Y também aumentam.\n",
    "•cov(X,Y) < 0: Se a covariância entre as dimensões X e Y for negativa, ambas as dimensões estão inversamente relacionadas entre si, ou seja, se os valores de X aumentam, os valores de Y diminuem. •\tcov(X,Y) = 0: Se a covariância entre as dimensões X e Y for nula, verifica-se que as dimensões são independentes uma da outra, como tal o comportamento da dimensão X não influencia o comportamento da dimensão Y. Variância:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x1   y1\n",
      "0 -0.69  0.4\n",
      "1  1.31 -1.3\n",
      "2 -0.39  0.9\n",
      "3 -0.09  0.2\n",
      "4 -1.29  1.0\n",
      "5 -0.49  0.7\n",
      "6 -0.19 -0.4\n",
      "7  0.81 -0.9\n",
      "8  0.31 -0.4\n",
      "9  0.71 -1.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m=np.array([x1,y1]).T\n",
    "df=pd.DataFrame(m,index=[i for i in range(len(x1))],columns=['x1','y1'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir da nova matriz, calculamos a matriz de covariância:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1        y1\n",
      "x  0.616556 -0.615444\n",
      "y -0.615444  0.716556\n"
     ]
    }
   ],
   "source": [
    "CovMatrix=np.cov(m.T)\n",
    "df=pd.DataFrame(CovMatrix,index=['x','y'],columns=['x1','y1'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3º) Calcular os Vetores Próprios e os Valores próprios a partir da matriz de covariância\n",
    "Os vetores próprios e os valores próprios representam as características principais de uma matriz. Relativamente aos vetores próprios, estes são caraterizados pelas seguintes propriedades:\n",
    "\n",
    "•\tApenas existem em matrizes quadradas (NxN)\n",
    "•\tNuma matriz NxN existe N vetores próprios\n",
    "•\tSão ortogonais entre si\n",
    "•\tSão calculados de modo a que o seu comprimento seja unitário.\n",
    "\n",
    "Para determinar os vetores próprios de uma matriz é necessário calcular primeiro os seus valores próprios. Os valores próprios são valores escalares que se obtêm resolvendo a seguinte equação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
